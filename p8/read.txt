Yes. And you should, otherwise you’re just eyeballing behaviour and hoping.

Let’s make this concrete. There are 3 levels you can use today:

1️⃣ Simple Manual Test Matrix (start here)

Make a table (in Notion/Excel/Google Sheets) with columns like:

#

user_input

expected_intent (greeting / service / contact / blog / casestudy / career / other)

expected_contact_mode (none / contact / done)

expected_business_count_change (0 or +1)

expect_contact_injection (yes/no)

notes

You already asked for lots of questions; convert them into rows.

Example rows:

#	user_input	expected_intent	contact_mode	business_count_change	expect_contact_injection
1	hi	greeting	none	0	no
2	what services do you offer?	service	none	+1	yes (after 2nd service)
3	how can I reach your sales team?	contact	contact	+1	no (in explicit flow)
4	sure, my email is test@mail.com
	contact	contact	0	no
5	my phone is 9876543210	contact	done	0	no

Use it as a checklist while you click through the UI.

2️⃣ CSV + small checker script (semi-automated)

If you want something more serious but still lightweight:

a) Make a test_cases.csv (text file)

Example content:

id,input,expected_intent,expect_contact_mode,expect_contact_field
1,"hi","greeting","none",false
2,"what services do you offer?","service","none",true
3,"how can I reach your sales team?","contact","contact",false
4,"sure, my email is test@mail.com","contact","contact",false
5,"my phone is 9876543210","contact","done",false
6,"show me blogs","blog","none",false
7,"show me case studies","casestudy","none",false


You can expand this with all the scenarios we listed.

b) Tiny Python script to call your /summarize and log behaviour

Assuming your API is running at http://localhost:8000/summarize:

import csv
import httpx

API_URL = "http://localhost:8000/summarize"

def main():
    session = httpx.Client()  # will reuse cookies -> same sid

    with open("test_cases.csv", newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            user_input = row["input"]
            print(f"\n=== Test {row['id']} ===")
            print(f"User: {user_input}")

            resp = session.post(API_URL, json={"query": user_input})
            resp.raise_for_status()
            data = resp.json()

            # Your API might use "raw_answer" or "summary" – handle both:
            answer = data.get("summary") or data.get("raw_answer") or ""
            contact_field = data.get("contact")

            print(f"Bot: {answer}")
            print(f"Contact field present? {bool(contact_field)} "
                  f"(expected: {row['expect_contact_field']})")

if __name__ == "__main__":
    main()


This doesn’t assert yet, it just prints mismatches so you can see:

Where contact shows up when it shouldn’t

Where contact injection is missing when it should exist

You can later turn those prints into assert calls if you want a proper test run.

3️⃣ Deeper: unit-ish tests for the classifier / injection logic

If you’re serious:

Pull your intent classification and contact injection into small pure functions (no FastAPI, no DB).

Write pytest tests that call them directly with strings and your fake state dict, and assert:

what business_count becomes,

what mode becomes (contact / done),

whether injection happens or not.

Example pattern:

def test_greeting_does_not_increment_business():
    state = {}
    intent = "greeting"
    new_state = apply_business_intent_state(state, intent)
    assert new_state.get("business_count", 0) == 0

def test_service_increments_business():
    state = {}
    intent = "service"
    new_state = apply_business_intent_state(state, intent)
    assert new_state["business_count"] == 1


But that requires you to have that logic factored out. Right now it’s buried inside summarize. If you want, we can refactor that next.

Pragmatic answer

Given where you are:

Do this now:

Make the CSV (or sheet).

Use the small Python script to drive your API and log behaviour.

Once it stabilises and you’re not fighting basic bugs, then we can refactor out the intent/injection logic and slap proper unit tests on it.

If you want, I can:

Generate a bigger test_cases.csv for you pre-filled with all the service/contact/blog/career/casestudy examples we discussed.

Or turn this into a Streamlit test harness where you click “Run all tests” and see pass/fail.
